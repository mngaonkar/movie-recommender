{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  time_stamp\n",
      "0      196       242       3   881250949\n",
      "1      186       302       3   891717742\n",
      "2       22       377       1   878887116\n",
      "3      244        51       2   880606923\n",
      "4      166       346       1   886397596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load movie dataset\n",
    "df = pd.read_csv('ml-100k/u.data', header=None, delim_whitespace=True)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 'time_stamp']\n",
    "print(df.head())\n",
    "\n",
    "# one hot code user id and movie id, needs to be in float32 for sagemaker\n",
    "X = df[['user_id', 'movie_id']]\n",
    "\n",
    "enc = OneHotEncoder(categories='auto', dtype='float32')\n",
    "enc.fit(X)\n",
    "one_hot_labels = enc.transform(X).toarray()\n",
    "\n",
    "# create target labels, needs to be in float32 for sagemaker\n",
    "df['rating'] = df['rating'].apply(lambda x : 1 if x >=4 else 0)\n",
    "target = df['rating'].as_matrix().astype('float32')\n",
    "\n",
    "# create new data frame\n",
    "df_temp = pd.DataFrame(one_hot_labels)\n",
    "df_temp.insert(one_hot_labels.shape[1], 'rating', df['rating'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_labels, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# convert train data to recordio protobuf\n",
    "train_data_buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(train_data_buffer, X_train, y_train)\n",
    "train_data_buffer.seek(0)\n",
    "\n",
    "# convert test data to recordio protobuf\n",
    "test_data_buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(test_data_buffer, X_test, y_test)\n",
    "test_data_buffer.seek(0)\n",
    "\n",
    "# df_temp.to_csv('train.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('ml-100k/u.user', header=None, delim_whitespace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-us-east-1-756448110530'\n",
    "prefix = 'movie-dateset'\n",
    "key = 'recordio-pb-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload train and test data to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(train_data_buffer)\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(test_data_buffer)\n",
    "\n",
    "# create train and test channel for training\n",
    "train_path = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "test_path = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_path, content_type='application/x-recordio-protobuf')\n",
    "s3_input_test = sagemaker.s3_input(s3_data=test_path, content_type='application/x-recordio-protobuf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, \"factorization-machines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                         'AmazonSageMaker-ExecutionRole-20190815T111389',\n",
    "                                         train_instance_count=1,\n",
    "                                         train_instance_type='ml.m5.large',\n",
    "                                         output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                         train_use_spot_instances=True,\n",
    "                                         train_max_run=3600,\n",
    "                                         train_max_wait=3600,\n",
    "                                         sagemaker_session=session,\n",
    "                                         input_mode='Pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(feature_dim=2625,\n",
    "                             predictor_type='binary_classifier',\n",
    "                             mini_batch_size=100,\n",
    "                             num_factors=64,\n",
    "                             epochs=10,\n",
    "                             linear_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-10 19:07:29 Starting - Starting the training job...\n",
      "2020-04-10 19:07:31 Starting - Launching requested ML instances......\n",
      "2020-04-10 19:08:40 Starting - Preparing the instances for training...\n",
      "2020-04-10 19:09:26 Downloading - Downloading input data...\n",
      "2020-04-10 19:10:17 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'predictor_type': u'binary_classifier', u'epochs': u'30', u'linear_lr': u'0.001', u'feature_dim': u'2625', u'num_factors': u'64', u'mini_batch_size': u'100'}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'30', u'feature_dim': u'2625', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'100', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'binary_classifier', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 WARNING 140314233935680] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] The channel 'train' is in pipe input mode under /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] The channel 'test' is in pipe input mode under /opt/ml/input/data/test.\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:10:19.471] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:10:19.482] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 16, \"num_examples\": 1, \"num_bytes\": 1054800}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] nvidia-smi took: 0.0251791477203 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] [Fully symbolic network] Building a fully symbolic network.\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 47.223806381225586, \"sum\": 47.223806381225586, \"min\": 47.223806381225586}}, \"EndTime\": 1586545819.527197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545819.465358}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586545819.530185, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545819.529842}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.51\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.692874145508\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:19 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_f_1.000 <score>=0.566371681416\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:36 INFO 140314233935680] Iter[0] Batch [500]#011Speed: 2997.72 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:36 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=500 train binary_classification_accuracy <score>=0.527944111776\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:36 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=500 train binary_classification_cross_entropy <loss>=8.27740780128\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:36 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, batch=500 train binary_f_1.000 <score>=0.572208957384\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:10:40.907] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 21329, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] Epoch[0] Train-binary_classification_accuracy=0.539687\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] Epoch[0] Train-binary_classification_cross_entropy=8.161573\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] Epoch[0] Train-binary_f_1.000=0.584067\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] Epoch[0] Time cost=21.355\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.539686567164\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=8.1615728803\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=0, train binary_f_1.000 <score>=0.584067216011\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}, \"update.time\": {\"count\": 1, \"max\": 21378.65686416626, \"sum\": 21378.65686416626, \"min\": 21378.65686416626}}, \"EndTime\": 1586545840.910772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545819.529747}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 671, \"sum\": 671.0, \"min\": 671}, \"Total Records Seen\": {\"count\": 1, \"max\": 67100, \"sum\": 67100.0, \"min\": 67100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1586545840.911157, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1586545819.532074}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=3133.83346492 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.58\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=7.73668579102\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:40 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_f_1.000 <score>=0.618181818182\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:10:55 INFO 140314233935680] Iter[1] Batch [500]#011Speed: 3356.76 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:55 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=500 train binary_classification_accuracy <score>=0.663473053892\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:55 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=500 train binary_classification_cross_entropy <loss>=6.17977654189\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:10:55 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, batch=500 train binary_f_1.000 <score>=0.695414965495\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:11:00.464] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 19551, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] Epoch[1] Train-binary_classification_accuracy=0.680015\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] Epoch[1] Train-binary_classification_cross_entropy=5.875615\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] Epoch[1] Train-binary_f_1.000=0.710522\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] Epoch[1] Time cost=19.553\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.680014925373\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=5.87561495288\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=1, train binary_f_1.000 <score>=0.710522407205\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 19556.42604827881, \"sum\": 19556.42604827881, \"min\": 19556.42604827881}}, \"EndTime\": 1586545860.46798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545840.910915}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1341, \"sum\": 1341.0, \"min\": 1341}, \"Total Records Seen\": {\"count\": 1, \"max\": 134100, \"sum\": 134100.0, \"min\": 134100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1586545860.468305, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1586545840.911516}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=3425.88683738 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.71\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=5.28539916992\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_f_1.000 <score>=0.756302521008\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:16 INFO 140314233935680] Iter[2] Batch [500]#011Speed: 3191.87 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:16 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=500 train binary_classification_accuracy <score>=0.760818363273\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:16 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=500 train binary_classification_cross_entropy <loss>=4.39328971817\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:16 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, batch=500 train binary_f_1.000 <score>=0.784047288652\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:11:20.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 20493, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] Epoch[2] Train-binary_classification_accuracy=0.768478\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] Epoch[2] Train-binary_classification_cross_entropy=4.253258\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] Epoch[2] Train-binary_f_1.000=0.790983\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] Epoch[2] Time cost=20.495\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.76847761194\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=4.2532583001\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=2, train binary_f_1.000 <score>=0.790982833428\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20514.700174331665, \"sum\": 20514.700174331665, \"min\": 20514.700174331665}}, \"EndTime\": 1586545880.983426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545860.468077}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2011, \"sum\": 2011.0, \"min\": 2011}, \"Total Records Seen\": {\"count\": 1, \"max\": 201100, \"sum\": 201100.0, \"min\": 201100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1586545880.983918, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1586545860.468691}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=3265.84377199 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:20 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:21 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.82\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:21 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=3.27493865967\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:21 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_f_1.000 <score>=0.847457627119\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:37 INFO 140314233935680] Iter[3] Batch [500]#011Speed: 3030.86 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:37 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=500 train binary_classification_accuracy <score>=0.812435129741\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:37 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=500 train binary_classification_cross_entropy <loss>=3.44770578746\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:37 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, batch=500 train binary_f_1.000 <score>=0.830754822326\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:11:42.550] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 21565, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] Epoch[3] Train-binary_classification_accuracy=0.816075\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] Epoch[3] Train-binary_classification_cross_entropy=3.379904\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] Epoch[3] Train-binary_f_1.000=0.833933\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] Epoch[3] Time cost=21.567\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.816074626866\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=3.37990441006\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=3, train binary_f_1.000 <score>=0.833933023381\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21569.88286972046, \"sum\": 21569.88286972046, \"min\": 21569.88286972046}}, \"EndTime\": 1586545902.554222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545880.983507}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2681, \"sum\": 2681.0, \"min\": 2681}, \"Total Records Seen\": {\"count\": 1, \"max\": 268100, \"sum\": 268100.0, \"min\": 268100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1586545902.554622, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1586545880.984309}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=3106.09628598 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.87\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=2.39468856812\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_f_1.000 <score>=0.890756302521\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:11:59 INFO 140314233935680] Iter[4] Batch [500]#011Speed: 2915.65 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=500 train binary_classification_accuracy <score>=0.849880239521\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=500 train binary_classification_cross_entropy <loss>=2.76073460349\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:11:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, batch=500 train binary_f_1.000 <score>=0.864469392536\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:12:05.046] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 22491, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] Epoch[4] Train-binary_classification_accuracy=0.854343\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] Epoch[4] Train-binary_classification_cross_entropy=2.678921\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] Epoch[4] Train-binary_f_1.000=0.868475\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] Epoch[4] Time cost=22.492\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.854343283582\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=2.67892144627\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=4, train binary_f_1.000 <score>=0.868475316379\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22495.11194229126, \"sum\": 22495.11194229126, \"min\": 22495.11194229126}}, \"EndTime\": 1586545925.050108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545902.55429}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3351, \"sum\": 3351.0, \"min\": 3351}, \"Total Records Seen\": {\"count\": 1, \"max\": 335100, \"sum\": 335100.0, \"min\": 335100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1586545925.05055, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1586545902.554957}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2978.33679284 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_accuracy <score>=0.87\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_cross_entropy <loss>=2.39468856812\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:05 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_f_1.000 <score>=0.888888888889\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:22 INFO 140314233935680] Iter[5] Batch [500]#011Speed: 2904.28 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=500 train binary_classification_accuracy <score>=0.87878243513\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=500 train binary_classification_cross_entropy <loss>=2.23003538935\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, batch=500 train binary_f_1.000 <score>=0.890669163051\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:12:27.639] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 22588, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] Epoch[5] Train-binary_classification_accuracy=0.881493\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] Epoch[5] Train-binary_classification_cross_entropy=2.180719\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] Epoch[5] Train-binary_f_1.000=0.893096\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] Epoch[5] Time cost=22.589\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, train binary_classification_accuracy <score>=0.881492537313\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy <loss>=2.18071896049\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=5, train binary_f_1.000 <score>=0.893095648427\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22592.02480316162, \"sum\": 22592.02480316162, \"min\": 22592.02480316162}}, \"EndTime\": 1586545947.643069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545925.050201}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4021, \"sum\": 4021.0, \"min\": 4021}, \"Total Records Seen\": {\"count\": 1, \"max\": 402100, \"sum\": 402100.0, \"min\": 402100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1586545947.643474, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1586545925.050983}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2965.56924771 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_accuracy <score>=0.94\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_cross_entropy <loss>=1.10524093628\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:27 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_f_1.000 <score>=0.949152542373\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:45 INFO 140314233935680] Iter[6] Batch [500]#011Speed: 2830.81 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=500 train binary_classification_accuracy <score>=0.899441117764\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=500 train binary_classification_cross_entropy <loss>=1.85071777131\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, batch=500 train binary_f_1.000 <score>=0.909215410675\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:12:50.806] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 23161, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] Epoch[6] Train-binary_classification_accuracy=0.900940\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] Epoch[6] Train-binary_classification_cross_entropy=1.822931\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] Epoch[6] Train-binary_f_1.000=0.910515\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] Epoch[6] Time cost=23.163\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, train binary_classification_accuracy <score>=0.900940298507\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy <loss>=1.82293129491\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=6, train binary_f_1.000 <score>=0.910515174803\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23165.804147720337, \"sum\": 23165.804147720337, \"min\": 23165.804147720337}}, \"EndTime\": 1586545970.809741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545947.643139}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4691, \"sum\": 4691.0, \"min\": 4691}, \"Total Records Seen\": {\"count\": 1, \"max\": 469100, \"sum\": 469100.0, \"min\": 469100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1586545970.810171, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1586545947.643903}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2892.11013222 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_accuracy <score>=0.91\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_cross_entropy <loss>=1.65786132813\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:12:50 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_f_1.000 <score>=0.924369747899\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:13:09 INFO 140314233935680] Iter[7] Batch [500]#011Speed: 2743.61 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:09 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=500 train binary_classification_accuracy <score>=0.913313373253\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:09 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=500 train binary_classification_cross_entropy <loss>=1.59284621431\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:09 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, batch=500 train binary_f_1.000 <score>=0.9218870843\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:13:14.738] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 23927, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] Epoch[7] Train-binary_classification_accuracy=0.915910\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] Epoch[7] Train-binary_classification_cross_entropy=1.545405\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] Epoch[7] Train-binary_f_1.000=0.924182\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] Epoch[7] Time cost=23.928\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, train binary_classification_accuracy <score>=0.915910447761\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy <loss>=1.54540522857\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=7, train binary_f_1.000 <score>=0.924182478805\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23930.781841278076, \"sum\": 23930.781841278076, \"min\": 23930.781841278076}}, \"EndTime\": 1586545994.741385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545970.809835}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5361, \"sum\": 5361.0, \"min\": 5361}, \"Total Records Seen\": {\"count\": 1, \"max\": 536100, \"sum\": 536100.0, \"min\": 536100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1586545994.741859, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1586545970.810563}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2799.66028891 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_accuracy <score>=0.94\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_cross_entropy <loss>=1.10524093628\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:14 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_f_1.000 <score>=0.949152542373\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:33 INFO 140314233935680] Iter[8] Batch [500]#011Speed: 2735.30 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:33 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=500 train binary_classification_accuracy <score>=0.929700598802\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:33 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=500 train binary_classification_cross_entropy <loss>=1.2930697076\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:33 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, batch=500 train binary_f_1.000 <score>=0.936570255376\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:13:38.785] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 24042, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] Epoch[8] Train-binary_classification_accuracy=0.930299\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] Epoch[8] Train-binary_classification_cross_entropy=1.282323\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] Epoch[8] Train-binary_f_1.000=0.937143\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] Epoch[8] Time cost=24.043\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, train binary_classification_accuracy <score>=0.930298507463\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy <loss>=1.28232319801\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=8, train binary_f_1.000 <score>=0.937143318617\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24046.704053878784, \"sum\": 24046.704053878784, \"min\": 24046.704053878784}}, \"EndTime\": 1586546018.789001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586545994.741484}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6031, \"sum\": 6031.0, \"min\": 6031}, \"Total Records Seen\": {\"count\": 1, \"max\": 603100, \"sum\": 603100.0, \"min\": 603100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1586546018.789246, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1586545994.742268}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2786.19468309 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_accuracy <score>=0.91\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_cross_entropy <loss>=1.65786132813\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_f_1.000 <score>=0.923076923077\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:57 INFO 140314233935680] Iter[9] Batch [500]#011Speed: 2649.17 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:57 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=500 train binary_classification_accuracy <score>=0.939141716567\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:57 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=500 train binary_classification_cross_entropy <loss>=1.11934143805\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:13:57 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, batch=500 train binary_f_1.000 <score>=0.945131278231\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:14:03.649] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 24859, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] Epoch[9] Train-binary_classification_accuracy=0.939418\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] Epoch[9] Train-binary_classification_cross_entropy=1.114122\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] Epoch[9] Train-binary_f_1.000=0.945383\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] Epoch[9] Time cost=24.860\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, train binary_classification_accuracy <score>=0.939417910448\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy <loss>=1.11412207737\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=9, train binary_f_1.000 <score>=0.945382617705\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24862.828969955444, \"sum\": 24862.828969955444, \"min\": 24862.828969955444}}, \"EndTime\": 1586546043.652388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546018.789073}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6701, \"sum\": 6701.0, \"min\": 6701}, \"Total Records Seen\": {\"count\": 1, \"max\": 670100, \"sum\": 670100.0, \"min\": 670100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1586546043.652708, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1586546018.789524}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2694.72787554 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_accuracy <score>=0.97\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_cross_entropy <loss>=0.552620429993\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_f_1.000 <score>=0.975609756098\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:14:22 INFO 140314233935680] Iter[10] Batch [500]#011Speed: 2654.16 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=500 train binary_classification_accuracy <score>=0.944231536926\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=500 train binary_classification_cross_entropy <loss>=1.0251873378\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, batch=500 train binary_f_1.000 <score>=0.949699348288\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:14:28.338] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 24685, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] Epoch[10] Train-binary_classification_accuracy=0.944955\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] Epoch[10] Train-binary_classification_cross_entropy=1.012048\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] Epoch[10] Train-binary_f_1.000=0.950334\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] Epoch[10] Time cost=24.686\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, train binary_classification_accuracy <score>=0.944955223881\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy <loss>=1.01204754912\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=10, train binary_f_1.000 <score>=0.950333979746\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24688.554048538208, \"sum\": 24688.554048538208, \"min\": 24688.554048538208}}, \"EndTime\": 1586546068.341665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546043.652477}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7371, \"sum\": 7371.0, \"min\": 7371}, \"Total Records Seen\": {\"count\": 1, \"max\": 737100, \"sum\": 737100.0, \"min\": 737100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1586546068.342021, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1586546043.653074}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2713.74465766 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_accuracy <score>=0.97\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_cross_entropy <loss>=0.552620429993\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:28 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_f_1.000 <score>=0.975609756098\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:47 INFO 140314233935680] Iter[11] Batch [500]#011Speed: 2624.25 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=500 train binary_classification_accuracy <score>=0.952954091816\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=500 train binary_classification_cross_entropy <loss>=0.865150829132\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, batch=500 train binary_f_1.000 <score>=0.95756746539\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:14:53.379] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 35, \"duration\": 25036, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] Epoch[11] Train-binary_classification_accuracy=0.953388\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] Epoch[11] Train-binary_classification_cross_entropy=0.857482\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] Epoch[11] Train-binary_f_1.000=0.957982\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] Epoch[11] Time cost=25.038\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, train binary_classification_accuracy <score>=0.953388059701\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy <loss>=0.857482261515\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=11, train binary_f_1.000 <score>=0.957981836529\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 25040.317058563232, \"sum\": 25040.317058563232, \"min\": 25040.317058563232}}, \"EndTime\": 1586546093.382733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546068.341762}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8041, \"sum\": 8041.0, \"min\": 8041}, \"Total Records Seen\": {\"count\": 1, \"max\": 804100, \"sum\": 804100.0, \"min\": 804100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1586546093.383056, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1586546068.342378}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2675.62545893 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_cross_entropy <loss>=0.368413619995\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:14:53 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_f_1.000 <score>=0.983606557377\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:12 INFO 140314233935680] Iter[12] Batch [500]#011Speed: 2566.12 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:12 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=500 train binary_classification_accuracy <score>=0.958283433134\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:12 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=500 train binary_classification_cross_entropy <loss>=0.766910326038\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:12 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, batch=500 train binary_f_1.000 <score>=0.962372173412\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:15:18.941] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 25557, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] Epoch[12] Train-binary_classification_accuracy=0.958597\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] Epoch[12] Train-binary_classification_cross_entropy=0.761298\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] Epoch[12] Train-binary_f_1.000=0.962652\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] Epoch[12] Time cost=25.559\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, train binary_classification_accuracy <score>=0.958597014925\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy <loss>=0.761298133992\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=12, train binary_f_1.000 <score>=0.962651802784\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 25561.77306175232, \"sum\": 25561.77306175232, \"min\": 25561.77306175232}}, \"EndTime\": 1586546118.945295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546093.382828}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8711, \"sum\": 8711.0, \"min\": 8711}, \"Total Records Seen\": {\"count\": 1, \"max\": 871100, \"sum\": 871100.0, \"min\": 871100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1586546118.945667, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1586546093.383469}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2621.0406336 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_accuracy <score>=0.95\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_cross_entropy <loss>=0.921033782959\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:18 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_f_1.000 <score>=0.957983193277\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:15:38 INFO 140314233935680] Iter[13] Batch [500]#011Speed: 2500.69 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=500 train binary_classification_accuracy <score>=0.958842315369\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=500 train binary_classification_cross_entropy <loss>=0.757727640118\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, batch=500 train binary_f_1.000 <score>=0.962888304957\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:15:45.068] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 41, \"duration\": 26121, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] Epoch[13] Train-binary_classification_accuracy=0.960015\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] Epoch[13] Train-binary_classification_cross_entropy=0.736045\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] Epoch[13] Train-binary_f_1.000=0.963938\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] Epoch[13] Time cost=26.123\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, train binary_classification_accuracy <score>=0.960014925373\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy <loss>=0.736045255348\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=13, train binary_f_1.000 <score>=0.963938133506\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26126.08790397644, \"sum\": 26126.08790397644, \"min\": 26126.08790397644}}, \"EndTime\": 1586546145.072222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546118.945371}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9381, \"sum\": 9381.0, \"min\": 9381}, \"Total Records Seen\": {\"count\": 1, \"max\": 938100, \"sum\": 938100.0, \"min\": 938100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1586546145.072602, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1586546118.946107}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2564.43259172 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_accuracy <score>=0.96\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_cross_entropy <loss>=0.73682723999\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:15:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_f_1.000 <score>=0.967213114754\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:04 INFO 140314233935680] Iter[14] Batch [500]#011Speed: 2524.15 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=500 train binary_classification_accuracy <score>=0.965888223553\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=500 train binary_classification_cross_entropy <loss>=0.627662997788\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, batch=500 train binary_f_1.000 <score>=0.969241014381\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:16:11.371] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 26298, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] Epoch[14] Train-binary_classification_accuracy=0.965806\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] Epoch[14] Train-binary_classification_cross_entropy=0.629279\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] Epoch[14] Train-binary_f_1.000=0.969167\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] Epoch[14] Time cost=26.299\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, train binary_classification_accuracy <score>=0.965805970149\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy <loss>=0.629279452851\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=14, train binary_f_1.000 <score>=0.969166790035\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26301.792860031128, \"sum\": 26301.792860031128, \"min\": 26301.792860031128}}, \"EndTime\": 1586546171.374822, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546145.072281}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10051, \"sum\": 10051.0, \"min\": 10051}, \"Total Records Seen\": {\"count\": 1, \"max\": 1005100, \"sum\": 1005100.0, \"min\": 1005100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1586546171.375134, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1586546145.072991}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2547.30166426 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_accuracy <score>=0.97\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_cross_entropy <loss>=0.552620429993\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:11 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_f_1.000 <score>=0.97520661157\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:31 INFO 140314233935680] Iter[15] Batch [500]#011Speed: 2457.72 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:31 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=500 train binary_classification_accuracy <score>=0.969301397206\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:31 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=500 train binary_classification_cross_entropy <loss>=0.565489165179\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:31 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, batch=500 train binary_f_1.000 <score>=0.972306251801\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:16:38.024] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 47, \"duration\": 26648, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] Epoch[15] Train-binary_classification_accuracy=0.969582\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] Epoch[15] Train-binary_classification_cross_entropy=0.560008\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] Epoch[15] Train-binary_f_1.000=0.972563\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] Epoch[15] Time cost=26.650\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, train binary_classification_accuracy <score>=0.969582089552\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, train binary_classification_cross_entropy <loss>=0.560008341092\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=15, train binary_f_1.000 <score>=0.97256253534\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26652.251958847046, \"sum\": 26652.251958847046, \"min\": 26652.251958847046}}, \"EndTime\": 1586546198.027806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546171.374908}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10721, \"sum\": 10721.0, \"min\": 10721}, \"Total Records Seen\": {\"count\": 1, \"max\": 1072100, \"sum\": 1072100.0, \"min\": 1072100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1586546198.02823, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1586546171.37552}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2513.7979523 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_f_1.000 <score>=0.99173553719\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:16:58 INFO 140314233935680] Iter[16] Batch [500]#011Speed: 2457.67 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:58 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=500 train binary_classification_accuracy <score>=0.971796407186\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:58 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=500 train binary_classification_cross_entropy <loss>=0.519076260968\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:16:58 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, batch=500 train binary_f_1.000 <score>=0.974599579356\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:17:04.813] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 26784, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] Epoch[16] Train-binary_classification_accuracy=0.971851\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] Epoch[16] Train-binary_classification_cross_entropy=0.518033\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] Epoch[16] Train-binary_f_1.000=0.974636\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] Epoch[16] Time cost=26.785\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, train binary_classification_accuracy <score>=0.971850746269\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, train binary_classification_cross_entropy <loss>=0.518032527041\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=16, train binary_f_1.000 <score>=0.974636219371\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26788.074016571045, \"sum\": 26788.074016571045, \"min\": 26788.074016571045}}, \"EndTime\": 1586546224.816905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546198.027888}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11391, \"sum\": 11391.0, \"min\": 11391}, \"Total Records Seen\": {\"count\": 1, \"max\": 1139100, \"sum\": 1139100.0, \"min\": 1139100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1586546224.81718, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1586546198.028797}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2501.04726066 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:04 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_f_1.000 <score>=0.99173553719\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:25 INFO 140314233935680] Iter[17] Batch [500]#011Speed: 2411.59 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:25 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=500 train binary_classification_accuracy <score>=0.972634730539\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:25 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=500 train binary_classification_cross_entropy <loss>=0.503105202939\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:25 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, batch=500 train binary_f_1.000 <score>=0.975351922766\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:17:32.044] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 53, \"duration\": 27226, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] Epoch[17] Train-binary_classification_accuracy=0.973179\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] Epoch[17] Train-binary_classification_cross_entropy=0.493325\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] Epoch[17] Train-binary_f_1.000=0.975845\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] Epoch[17] Time cost=27.227\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, train binary_classification_accuracy <score>=0.973179104478\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, train binary_classification_cross_entropy <loss>=0.493325087135\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=17, train binary_f_1.000 <score>=0.975845150884\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27229.12907600403, \"sum\": 27229.12907600403, \"min\": 27229.12907600403}}, \"EndTime\": 1586546252.046953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546224.816993}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12061, \"sum\": 12061.0, \"min\": 12061}, \"Total Records Seen\": {\"count\": 1, \"max\": 1206100, \"sum\": 1206100.0, \"min\": 1206100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1586546252.047208, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1586546224.817791}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2460.56088593 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_cross_entropy <loss>=0.368413619995\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_f_1.000 <score>=0.983606557377\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:52 INFO 140314233935680] Iter[18] Batch [500]#011Speed: 2443.26 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:52 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=500 train binary_classification_accuracy <score>=0.974690618762\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:52 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=500 train binary_classification_cross_entropy <loss>=0.465970972788\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:52 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, batch=500 train binary_f_1.000 <score>=0.977170429585\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:17:59.021] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 26972, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] Epoch[18] Train-binary_classification_accuracy=0.974731\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] Epoch[18] Train-binary_classification_cross_entropy=0.464996\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] Epoch[18] Train-binary_f_1.000=0.977199\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] Epoch[18] Time cost=26.974\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, train binary_classification_accuracy <score>=0.974731343284\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, train binary_classification_cross_entropy <loss>=0.464996132922\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=18, train binary_f_1.000 <score>=0.977198960283\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26976.738929748535, \"sum\": 26976.738929748535, \"min\": 26976.738929748535}}, \"EndTime\": 1586546279.024242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546252.047034}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12731, \"sum\": 12731.0, \"min\": 12731}, \"Total Records Seen\": {\"count\": 1, \"max\": 1273100, \"sum\": 1273100.0, \"min\": 1273100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1586546279.024617, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1586546252.047469}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2483.57016265 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_accuracy <score>=0.97\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_cross_entropy <loss>=0.552620429993\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:17:59 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_f_1.000 <score>=0.974789915966\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:18:20 INFO 140314233935680] Iter[19] Batch [500]#011Speed: 2386.56 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=500 train binary_classification_accuracy <score>=0.976067864271\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=500 train binary_classification_cross_entropy <loss>=0.440450917927\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:20 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, batch=500 train binary_f_1.000 <score>=0.978430984547\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:18:26.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 59, \"duration\": 27386, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] Epoch[19] Train-binary_classification_accuracy=0.976806\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] Epoch[19] Train-binary_classification_cross_entropy=0.426954\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] Epoch[19] Train-binary_f_1.000=0.979094\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] Epoch[19] Time cost=27.387\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, train binary_classification_accuracy <score>=0.976805970149\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, train binary_classification_cross_entropy <loss>=0.426954221121\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=19, train binary_f_1.000 <score>=0.979093795404\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27389.6381855011, \"sum\": 27389.6381855011, \"min\": 27389.6381855011}}, \"EndTime\": 1586546306.414681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546279.024327}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13401, \"sum\": 13401.0, \"min\": 13401}, \"Total Records Seen\": {\"count\": 1, \"max\": 1340100, \"sum\": 1340100.0, \"min\": 1340100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1586546306.415105, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1586546279.025007}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2446.12528788 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_accuracy <score>=0.97\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_cross_entropy <loss>=0.552620429993\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:26 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_f_1.000 <score>=0.975609756098\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:47 INFO 140314233935680] Iter[20] Batch [500]#011Speed: 2346.46 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=500 train binary_classification_accuracy <score>=0.978463073852\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=500 train binary_classification_cross_entropy <loss>=0.39672399052\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:47 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, batch=500 train binary_f_1.000 <score>=0.980597363831\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:18:54.341] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 27925, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] Epoch[20] Train-binary_classification_accuracy=0.977791\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] Epoch[20] Train-binary_classification_cross_entropy=0.408957\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] Epoch[20] Train-binary_f_1.000=0.979985\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] Epoch[20] Time cost=27.926\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, train binary_classification_accuracy <score>=0.977791044776\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, train binary_classification_cross_entropy <loss>=0.408956774636\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=20, train binary_f_1.000 <score>=0.979984934897\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27928.902864456177, \"sum\": 27928.902864456177, \"min\": 27928.902864456177}}, \"EndTime\": 1586546334.344448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546306.41477}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14071, \"sum\": 14071.0, \"min\": 14071}, \"Total Records Seen\": {\"count\": 1, \"max\": 1407100, \"sum\": 1407100.0, \"min\": 1407100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1586546334.344828, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1586546306.415505}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2398.8959244 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:18:54 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_f_1.000 <score>=0.99173553719\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:15 INFO 140314233935680] Iter[21] Batch [500]#011Speed: 2352.92 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:15 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=500 train binary_classification_accuracy <score>=0.979201596806\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:15 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=500 train binary_classification_cross_entropy <loss>=0.382864668117\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:15 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, batch=500 train binary_f_1.000 <score>=0.981249550133\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:19:22.075] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 65, \"duration\": 27729, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] Epoch[21] Train-binary_classification_accuracy=0.979119\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] Epoch[21] Train-binary_classification_cross_entropy=0.384151\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] Epoch[21] Train-binary_f_1.000=0.981174\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] Epoch[21] Time cost=27.731\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, train binary_classification_accuracy <score>=0.979119402985\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, train binary_classification_cross_entropy <loss>=0.384151414416\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=21, train binary_f_1.000 <score>=0.98117371587\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27733.06703567505, \"sum\": 27733.06703567505, \"min\": 27733.06703567505}}, \"EndTime\": 1586546362.078379, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546334.344534}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14741, \"sum\": 14741.0, \"min\": 14741}, \"Total Records Seen\": {\"count\": 1, \"max\": 1474100, \"sum\": 1474100.0, \"min\": 1474100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1586546362.078693, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1586546334.345276}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2415.83946409 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:22 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_f_1.000 <score>=0.991869918699\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:19:42 INFO 140314233935680] Iter[22] Batch [500]#011Speed: 2400.25 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=500 train binary_classification_accuracy <score>=0.98119760479\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=500 train binary_classification_cross_entropy <loss>=0.346352925253\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:42 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, batch=500 train binary_f_1.000 <score>=0.983075209314\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:19:49.455] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 27375, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] Epoch[22] Train-binary_classification_accuracy=0.981657\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] Epoch[22] Train-binary_classification_cross_entropy=0.337896\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] Epoch[22] Train-binary_f_1.000=0.983478\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] Epoch[22] Time cost=27.376\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, train binary_classification_accuracy <score>=0.981656716418\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, train binary_classification_cross_entropy <loss>=0.337895776436\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=22, train binary_f_1.000 <score>=0.983478295939\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27379.805088043213, \"sum\": 27379.805088043213, \"min\": 27379.805088043213}}, \"EndTime\": 1586546389.45896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546362.078464}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15411, \"sum\": 15411.0, \"min\": 15411}, \"Total Records Seen\": {\"count\": 1, \"max\": 1541100, \"sum\": 1541100.0, \"min\": 1541100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1586546389.459285, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1586546362.079126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2447.01490574 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_accuracy <score>=0.96\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_cross_entropy <loss>=0.73682723999\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:19:49 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_f_1.000 <score>=0.966666666667\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:10 INFO 140314233935680] Iter[23] Batch [500]#011Speed: 2361.68 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=500 train binary_classification_accuracy <score>=0.98245508982\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=500 train binary_classification_cross_entropy <loss>=0.322922691528\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, batch=500 train binary_f_1.000 <score>=0.984179550404\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:20:17.294] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 71, \"duration\": 27834, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] Epoch[23] Train-binary_classification_accuracy=0.982896\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] Epoch[23] Train-binary_classification_cross_entropy=0.314876\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] Epoch[23] Train-binary_f_1.000=0.984582\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] Epoch[23] Time cost=27.835\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, train binary_classification_accuracy <score>=0.982895522388\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, train binary_classification_cross_entropy <loss>=0.3148760606\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=23, train binary_f_1.000 <score>=0.984581853407\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 27842.041015625, \"sum\": 27842.041015625, \"min\": 27842.041015625}}, \"EndTime\": 1586546417.301715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546389.459021}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16081, \"sum\": 16081.0, \"min\": 16081}, \"Total Records Seen\": {\"count\": 1, \"max\": 1608100, \"sum\": 1608100.0, \"min\": 1608100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1586546417.30198, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1586546389.459641}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2406.39440473 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:17 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_f_1.000 <score>=0.991869918699\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:38 INFO 140314233935680] Iter[24] Batch [500]#011Speed: 2330.80 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=500 train binary_classification_accuracy <score>=0.983552894212\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=500 train binary_classification_cross_entropy <loss>=0.301982807494\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:38 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, batch=500 train binary_f_1.000 <score>=0.985179856115\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:20:45.479] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 28176, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] Epoch[24] Train-binary_classification_accuracy=0.983761\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] Epoch[24] Train-binary_classification_cross_entropy=0.298137\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] Epoch[24] Train-binary_f_1.000=0.985363\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] Epoch[24] Time cost=28.177\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, train binary_classification_accuracy <score>=0.98376119403\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, train binary_classification_cross_entropy <loss>=0.298137331445\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=24, train binary_f_1.000 <score>=0.98536335997\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28181.724071502686, \"sum\": 28181.724071502686, \"min\": 28181.724071502686}}, \"EndTime\": 1586546445.484008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546417.301781}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16751, \"sum\": 16751.0, \"min\": 16751}, \"Total Records Seen\": {\"count\": 1, \"max\": 1675100, \"sum\": 1675100.0, \"min\": 1675100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1586546445.484254, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1586546417.302252}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2377.39235801 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_cross_entropy <loss>=0.184206809998\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:20:45 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_f_1.000 <score>=0.99173553719\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:21:06 INFO 140314233935680] Iter[25] Batch [500]#011Speed: 2334.69 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:06 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=500 train binary_classification_accuracy <score>=0.984291417166\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:06 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=500 train binary_classification_cross_entropy <loss>=0.288811348936\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:06 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, batch=500 train binary_f_1.000 <score>=0.985836407811\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:21:13.652] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 77, \"duration\": 28167, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] Epoch[25] Train-binary_classification_accuracy=0.984149\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] Epoch[25] Train-binary_classification_cross_entropy=0.291344\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] Epoch[25] Train-binary_f_1.000=0.985712\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] Epoch[25] Time cost=28.168\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, train binary_classification_accuracy <score>=0.984149253731\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, train binary_classification_cross_entropy <loss>=0.291343951837\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=25, train binary_f_1.000 <score>=0.985711594866\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28175.445079803467, \"sum\": 28175.445079803467, \"min\": 28175.445079803467}}, \"EndTime\": 1586546473.659994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546445.484075}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 17421, \"sum\": 17421.0, \"min\": 17421}, \"Total Records Seen\": {\"count\": 1, \"max\": 1742100, \"sum\": 1742100.0, \"min\": 1742100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 53, \"sum\": 53.0, \"min\": 53}}, \"EndTime\": 1586546473.660371, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1586546445.484519}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2377.91079142 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_cross_entropy <loss>=0.368413619995\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:13 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_f_1.000 <score>=0.983606557377\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:35 INFO 140314233935680] Iter[26] Batch [500]#011Speed: 2346.67 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:35 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=500 train binary_classification_accuracy <score>=0.985748502994\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:35 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=500 train binary_classification_cross_entropy <loss>=0.261997459349\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:35 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, batch=500 train binary_f_1.000 <score>=0.987150415722\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:21:41.847] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 28185, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] Epoch[26] Train-binary_classification_accuracy=0.985373\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] Epoch[26] Train-binary_classification_cross_entropy=0.268974\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] Epoch[26] Train-binary_f_1.000=0.986818\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] Epoch[26] Time cost=28.187\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, train binary_classification_accuracy <score>=0.985373134328\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, train binary_classification_cross_entropy <loss>=0.268974073232\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=26, train binary_f_1.000 <score>=0.98681768045\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28189.41020965576, \"sum\": 28189.41020965576, \"min\": 28189.41020965576}}, \"EndTime\": 1586546501.850199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546473.660059}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18091, \"sum\": 18091.0, \"min\": 18091}, \"Total Records Seen\": {\"count\": 1, \"max\": 1809100, \"sum\": 1809100.0, \"min\": 1809100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}}, \"EndTime\": 1586546501.850518, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1586546473.660736}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2376.73238723 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_cross_entropy <loss>=0.368413619995\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:21:41 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_f_1.000 <score>=0.983333333333\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:03 INFO 140314233935680] Iter[27] Batch [500]#011Speed: 2269.07 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=500 train binary_classification_accuracy <score>=0.986027944112\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=500 train binary_classification_cross_entropy <loss>=0.256997696254\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:03 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, batch=500 train binary_f_1.000 <score>=0.987403275148\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:22:10.716] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 83, \"duration\": 28864, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] Epoch[27] Train-binary_classification_accuracy=0.986164\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] Epoch[27] Train-binary_classification_cross_entropy=0.254583\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] Epoch[27] Train-binary_f_1.000=0.987526\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] Epoch[27] Time cost=28.866\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, train binary_classification_accuracy <score>=0.986164179104\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, train binary_classification_cross_entropy <loss>=0.254583416796\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=27, train binary_f_1.000 <score>=0.987525735739\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28869.391918182373, \"sum\": 28869.391918182373, \"min\": 28869.391918182373}}, \"EndTime\": 1586546530.720295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546501.850289}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18761, \"sum\": 18761.0, \"min\": 18761}, \"Total Records Seen\": {\"count\": 1, \"max\": 1876100, \"sum\": 1876100.0, \"min\": 1876100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 57, \"sum\": 57.0, \"min\": 57}}, \"EndTime\": 1586546530.720613, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1586546501.850873}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2320.75725604 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_cross_entropy <loss>=0.368413619995\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:10 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_f_1.000 <score>=0.983606557377\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/10/2020 19:22:32 INFO 140314233935680] Iter[28] Batch [500]#011Speed: 2302.78 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=500 train binary_classification_accuracy <score>=0.986067864271\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=500 train binary_classification_cross_entropy <loss>=0.256022356107\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:32 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, batch=500 train binary_f_1.000 <score>=0.987443333093\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:22:39.284] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 28563, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] Epoch[28] Train-binary_classification_accuracy=0.986104\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] Epoch[28] Train-binary_classification_cross_entropy=0.255504\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] Epoch[28] Train-binary_f_1.000=0.987475\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] Epoch[28] Time cost=28.564\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, train binary_classification_accuracy <score>=0.986104477612\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, train binary_classification_cross_entropy <loss>=0.255503563065\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=28, train binary_f_1.000 <score>=0.98747494316\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28566.186904907227, \"sum\": 28566.186904907227, \"min\": 28566.186904907227}}, \"EndTime\": 1586546559.287093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546530.720357}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19431, \"sum\": 19431.0, \"min\": 19431}, \"Total Records Seen\": {\"count\": 1, \"max\": 1943100, \"sum\": 1943100.0, \"min\": 1943100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 59, \"sum\": 59.0, \"min\": 59}}, \"EndTime\": 1586546559.287335, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1586546530.720873}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2345.39669784 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 WARNING 140314233935680] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 WARNING 140314233935680] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_accuracy <score>=1.0\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_cross_entropy <loss>=0.0\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:22:39 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_f_1.000 <score>=1.0\u001b[0m\n",
      "\n",
      "2020-04-10 19:23:14 Uploading - Uploading generated training model\u001b[34m[04/10/2020 19:23:00 INFO 140314233935680] Iter[29] Batch [500]#011Speed: 2331.10 samples/sec\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=500 train binary_classification_accuracy <score>=0.986786427146\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=500 train binary_classification_cross_entropy <loss>=0.243403535679\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:00 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, batch=500 train binary_f_1.000 <score>=0.988096522458\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:23:07.681] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 89, \"duration\": 28393, \"num_examples\": 670, \"num_bytes\": 706716000}\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] Epoch[29] Train-binary_classification_accuracy=0.986761\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] Epoch[29] Train-binary_classification_cross_entropy=0.243868\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] Epoch[29] Train-binary_f_1.000=0.988074\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] Epoch[29] Time cost=28.395\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, train binary_classification_accuracy <score>=0.98676119403\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, train binary_classification_cross_entropy <loss>=0.243868214422\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, epoch=29, train binary_f_1.000 <score>=0.988073628871\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.98676119403\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, train binary_classification_cross_entropy <loss>=0.243868214422\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.988073628871\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28397.76587486267, \"sum\": 28397.76587486267, \"min\": 28397.76587486267}}, \"EndTime\": 1586546587.68539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546559.287168}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 670, \"sum\": 670.0, \"min\": 670}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20101, \"sum\": 20101.0, \"min\": 20101}, \"Total Records Seen\": {\"count\": 1, \"max\": 2010100, \"sum\": 2010100.0, \"min\": 2010100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67000, \"sum\": 67000.0, \"min\": 67000}, \"Reset Count\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}}, \"EndTime\": 1586546587.685763, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1586546559.287591}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] #throughput_metric: host=algo-1, train throughput=2359.29473452 records/second\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 WARNING 140314233935680] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.03314018249511719, \"sum\": 0.03314018249511719, \"min\": 0.03314018249511719}}, \"EndTime\": 1586546587.686437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546587.685476}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:07 INFO 140314233935680] Saved checkpoint to \"/tmp/tmpYH6jAU/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:23:07.700] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 768228, \"num_examples\": 1, \"num_bytes\": 1054800}\u001b[0m\n",
      "\u001b[34m[2020-04-10 19:23:12.538] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 4838, \"num_examples\": 330, \"num_bytes\": 348084000}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 330, \"sum\": 330.0, \"min\": 330}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 330, \"sum\": 330.0, \"min\": 330}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 33000, \"sum\": 33000.0, \"min\": 33000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 330, \"sum\": 330.0, \"min\": 330}, \"Total Records Seen\": {\"count\": 1, \"max\": 33000, \"sum\": 33000.0, \"min\": 33000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 33000, \"sum\": 33000.0, \"min\": 33000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1586546592.538542, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546587.691814}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #test_score (algo-1) : ('binary_classification_accuracy', 0.6205757575757576)\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #test_score (algo-1) : ('binary_classification_cross_entropy', 6.9881273304332385)\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #test_score (algo-1) : ('binary_f_1.000', 0.6604842864502833)\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.620575757576\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=6.98812733043\u001b[0m\n",
      "\u001b[34m[04/10/2020 19:23:12 INFO 140314233935680] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.66048428645\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 773143.4350013733, \"sum\": 773143.4350013733, \"min\": 773143.4350013733}, \"setuptime\": {\"count\": 1, \"max\": 47.52397537231445, \"sum\": 47.52397537231445, \"min\": 47.52397537231445}}, \"EndTime\": 1586546592.555865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1586546587.686484}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-10 19:23:21 Completed - Training job completed\n",
      "Training seconds: 835\n",
      "Billable seconds: 365\n",
      "Managed Spot Training savings: 56.3%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "  'train': s3_input_train,\n",
    "    'test': s3_input_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = estimator.deploy(initial_instance_count=1,\n",
    "                         instance_type='ml.c4.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "def fm_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    js['instances'].append({'features': data.tolist()})\n",
    "    return json.dumps(js)\n",
    "\n",
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4.0\n",
      "{'predictions': [{'score': -1285.267578125}]}\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1000])\n",
    "prediction = X_test[1000]\n",
    "result = fm_predictor.predict(prediction)\n",
    "\n",
    "print(y_test[1000])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.delete_endpoint(fm_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
